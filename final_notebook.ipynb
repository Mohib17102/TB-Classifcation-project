{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81db9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet101V2, ResNet152V2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import DenseNet201\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05184b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile; zipfile.ZipFile('/content/drive/MyDrive/tb/tbdata.zip','r').extractall('TB DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ede53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.vgg16.preprocess_input,  # Preprocess input for VGG16\n",
    "    rotation_range=30,  # Rotate images by up to 30 degrees\n",
    "    zoom_range=0.2,  # Random zoom\n",
    "    width_shift_range=0.2,  # Randomly shift the image horizontally (by 20% of width)\n",
    "    height_shift_range=0.2,  # Randomly shift the image vertically (by 20% of height)\n",
    "    shear_range=0.2,  # Apply shear transformations\n",
    "    brightness_range=[0.8, 1.2],  # Random brightness adjustments\n",
    "    horizontal_flip=True,  # Flip images horizontally\n",
    "    vertical_flip=False,  # Set to True if vertical flipping is needed\n",
    "    fill_mode='nearest',  # How to fill pixels that are missing after a transformation\n",
    "    validation_split=0.2  # 20% of the data for validation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir_path = '/kaggle/input/tb-classifi/Type of tb'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b0df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106a08ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = {\n",
    "    'VGG16': VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'VGG19': VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'ResNet50': ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'ResNet101': ResNet101V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'ResNet152': ResNet152V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'InceptionV3': InceptionV3(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "    'DenseNet201' : DenseNet201(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "    'EfficientNetB3' : EfficientNetB3(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "    'MobileNet' : MobileNet(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa18e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Custom preprocessing function to adjust contrast\n",
    "def custom_preprocessing(image):\n",
    "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "    image = tf.image.adjust_contrast(image, contrast_factor=0.5)  # Adjust contrast\n",
    "    return image\n",
    "\n",
    "# Define directory path\n",
    "dir_path = '/kaggle/input/tb-classifi/Type of tb'\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=custom_preprocessing,  # Custom preprocessing function\n",
    "    rotation_range=30,  # Rotate images by up to 30 degrees\n",
    "    zoom_range=0.2,  # Random zoom\n",
    "    width_shift_range=0.2,  # Randomly shift the image horizontally (by 20% of width)\n",
    "    height_shift_range=0.2,  # Randomly shift the image vertically (by 20% of height)\n",
    "    shear_range=0.2,  # Apply shear transformations\n",
    "    brightness_range=[0.8, 1.2],  # Random brightness adjustments\n",
    "    horizontal_flip=True,  # Flip images horizontally\n",
    "    vertical_flip=True,  # Added vertical flip\n",
    "    fill_mode='nearest',  # How to fill pixels that are missing after a transformation\n",
    "    validation_split=0.2  # 20% of the data for validation\n",
    ")\n",
    "\n",
    "# Train and Validation generators\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dir_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    dir_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# List of base models to use (VGG16, VGG19, ResNet50, ResNet101)\n",
    "base_models = {\n",
    "    'VGG16': tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'VGG19': tf.keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'ResNet50': tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'ResNet101': tf.keras.applications.ResNet101V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'ResNet152': tf.keras.applications.ResNet152V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'InceptionV3': tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'DenseNet201': tf.keras.applications.DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'EfficientNetB3': tf.keras.applications.EfficientNetB3(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'MobileNet': tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "}\n",
    "\n",
    "\n",
    "# Training loop for each model\n",
    "for model_name, base_model in base_models.items():\n",
    "    print(f\"Training {model_name}\")\n",
    "\n",
    "    # Freeze base model layers initially\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Custom layers\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    predictions = layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "    # Final model\n",
    "    proposed_model = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "    proposed_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=[tf.keras.metrics.CategoricalAccuracy(),\n",
    "                                    tf.keras.metrics.Precision(),\n",
    "                                    tf.keras.metrics.Recall()])\n",
    "\n",
    "    # Callbacks\n",
    "    # Callbacks\n",
    "    check_point = ModelCheckpoint(f'{model_name}_best_model.keras', save_best_only=True)\n",
    "    earlystopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3)\n",
    "\n",
    "\n",
    "    # Initial Training\n",
    "    history = proposed_model.fit(train_generator,\n",
    "                                 epochs=20,\n",
    "                                 validation_data=validation_generator,\n",
    "                                 callbacks=[check_point, earlystopping, reduce_lr],\n",
    "                                 class_weight=class_weight_dict)\n",
    "\n",
    "    # Unfreeze last layers for fine-tuning\n",
    "    for layer in base_model.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Fine-tuning the model with a lower learning rate\n",
    "    proposed_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "    history_fine_tuning = proposed_model.fit(train_generator,\n",
    "                                             epochs=20,\n",
    "                                             validation_data=validation_generator,\n",
    "                                             callbacks=[check_point, earlystopping, reduce_lr],\n",
    "                                             class_weight=class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_individual_model_accuracy(history, history_fine_tuning, model_name):\n",
    "    acc = history.history['categorical_accuracy']\n",
    "    val_acc = history.history['val_categorical_accuracy']\n",
    "\n",
    "    acc_ft = history_fine_tuning.history['accuracy']\n",
    "    val_acc_ft = history_fine_tuning.history['val_accuracy']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(acc + acc_ft, label='Training Accuracy')\n",
    "    plt.plot(val_acc + val_acc_ft, label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for each model:\n",
    "for model_name in base_models.keys():\n",
    "    plot_individual_model_accuracy(history, history_fine_tuning, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f20fc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_individual_model_accuracy_and_loss(history, history_fine_tuning, model_name):\n",
    "    # Accuracy\n",
    "    acc = history.history['categorical_accuracy']\n",
    "    val_acc = history.history['val_categorical_accuracy']\n",
    "    acc_ft = history_fine_tuning.history['accuracy']\n",
    "    val_acc_ft = history_fine_tuning.history['val_accuracy']\n",
    "\n",
    "    # Loss\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    loss_ft = history_fine_tuning.history['loss']\n",
    "    val_loss_ft = history_fine_tuning.history['val_loss']\n",
    "\n",
    "    # Plotting Accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(acc + acc_ft, label='Training Accuracy')\n",
    "    plt.plot(val_acc + val_acc_ft, label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting Loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(loss + loss_ft, label='Training Loss')\n",
    "    plt.plot(val_loss + val_loss_ft, label='Validation Loss')\n",
    "    plt.title(f'{model_name} Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for each model:\n",
    "for model_name in base_models.keys():\n",
    "    plot_individual_model_accuracy_and_loss(history, history_fine_tuning, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c20f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdb1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Function to plot the confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Normalize the confusion matrix\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.set(font_scale=1.2)\n",
    "    \n",
    "    # Use heatmap to visualize the confusion matrix\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "    plt.title('Normalized Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `y_true` is the true labels and `y_pred` is the predicted labels.\n",
    "# Replace with actual true and predicted labels from your dataset.\n",
    "# For 5 classes: COVID, Extrapulmonary TB, Miliary TB, Normal, Pneumonia\n",
    "class_names = ['COVID', 'Extrapulmonary TB', 'Miliary TB', 'Normal', 'Pneumonia']\n",
    "\n",
    "# Example true and predicted labels\n",
    "y_true = [0, 1, 2, 2, 4, 3, 1, 0]  # Actual class indices\n",
    "y_pred = [0, 1, 2, 3, 4, 3, 1, 0]  # Predicted class indices\n",
    "\n",
    "# Call the function\n",
    "plot_confusion_matrix(y_true, y_pred, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739a208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8e5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Function to load the model, preprocess the image, and make predictions\n",
    "def predict_image_class(model_path, img_path, target_size=(224, 224), class_names=None):\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = tf.keras.applications.vgg16.preprocess_input(img_array)  # Adjust if needed for different models\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "\n",
    "    # Display the image and prediction\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.title(f\"Predicted Class: {class_names[predicted_class[0]]}\" if class_names else f\"Predicted Class ID: {predicted_class[0]}\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Define the path to your image and model\n",
    "img_path = \"/kaggle/input/tb-classifi/Type of tb/Normal/NORMAL (1154).png\"  # Change this to your test image path\n",
    "model_path = \"VGG16_best_model.keras\"  # Change this to your model path\n",
    "class_names = ['COVID', 'Extrapulmonary TB', 'Miliary TB', 'Normal', 'Pneumonia']  # List of class names\n",
    "\n",
    "predict_image_class(model_path, img_path, target_size=(224, 224), class_names=class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d161c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b440643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a8f631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c970cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8d418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
